{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxaMTckGDGgc"
      },
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n",
        "\n",
        "AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Program Operacyjny Polska Cyfrowa na lata 2014-2020\n",
        "<hr>\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n",
        "\n",
        "<center>\n",
        "Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego\n",
        "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
        "Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\"\n",
        "Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n",
        "    </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFrkgOd8e42J"
      },
      "source": [
        "# Laboratory Scenario 2 - Backpropagation and Gradient Checkpointing\n",
        "\n",
        "In this lab scenario, you are given an implementation of a simple neural network, and your goal is to implement the backpropagation procedure for this network.  \n",
        "\n",
        "To be more precise, the network inputs a tensor $x$ of shape `(MINI_BATCH_SIZE, 28*28)`, where each element of the batch represents a flattened grayscale image of shape `(28, 28)`.  \n",
        "In exercise 1, you can assume that images in the minibatch are fed to the network one by one (as tensors of shape `(1, 28*28)` - single image and `(1, 10)` - image class).  \n",
        "In exercise 2 you are asked to make the backpropagation work without this assumption, on whole mini-batches.  \n",
        "In exercise 3, you will implement a technique called *gradient checkpointing*, that allows you to reduce the amount of memory used to store activations for backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y4l5BmxTNNU"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import Sequence, Iterator, cast\n",
        "from typing_extensions import override\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "from numpy.typing import NDArray\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "FloatNDArray = NDArray[np.float64]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4UpigUXf4Xt"
      },
      "source": [
        "## Loading the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHhqeGLsHcYl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "825f266f-a12c-4bc6-c095-16ca47b4792d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-10 10:25:38 URL:https://s3.amazonaws.com/img-datasets/mnist.npz [11490434/11490434] -> \"mnist.npz\" [1]\n"
          ]
        }
      ],
      "source": [
        "!wget --no-verbose -O mnist.npz https://s3.amazonaws.com/img-datasets/mnist.npz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uutaqUkuVAuF"
      },
      "outputs": [],
      "source": [
        "def load_mnist(\n",
        "    path: Path = Path('mnist.npz')\n",
        ") -> tuple[FloatNDArray, FloatNDArray, FloatNDArray, FloatNDArray]:\n",
        "    '''\n",
        "    Load the MNIST dataset (grayscale 28 x 28 images of hand-written digits).\n",
        "\n",
        "    Returns tuple of:\n",
        "    - x_train: shape (N_train, H * W), grayscale values 0..1.\n",
        "    - y_train: shape (N_train, 10), one-hot-encoded label, dtype float64.\n",
        "    - x_test: shape (N_test, H * W), grayscale values 0..1.\n",
        "    - y_train: shape (N_test, 10), one-hot-encoded label, dtype float64.\n",
        "\n",
        "    More: https://en.wikipedia.org/wiki/MNIST_database\n",
        "    '''\n",
        "    with np.load(path) as f:\n",
        "        x_train, _y_train = f['x_train'], f['y_train']\n",
        "        x_test, _y_test = f['x_test'], f['y_test']\n",
        "\n",
        "    H = W = 28\n",
        "    N_train = len(x_train)\n",
        "    N_test = len(x_test)\n",
        "    assert x_train.shape == (N_train, H, W) and _y_train.shape == (N_train,)\n",
        "    assert x_test.shape == (N_test, H, W) and _y_test.shape == (N_test,)\n",
        "\n",
        "    x_train = x_train.reshape(N_train, H * W) / 255.0\n",
        "    x_test = x_test.reshape(N_test, H * W) / 255.0\n",
        "\n",
        "    y_train = np.zeros((N_train, 10), dtype=np.float64)\n",
        "    y_train[np.arange(N_train), _y_train] = 1\n",
        "\n",
        "    y_test = np.zeros((N_test, 10))\n",
        "    y_test[np.arange(N_test), _y_test] = 1\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "x_train, y_train, x_test, y_test = load_mnist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-icrjrxmizjf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "ddc8d438-ada9-4baa-f346-0d5f32fde03d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2688813958.py:6: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = PIL.Image.fromarray(x_int, mode='L')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=280x280>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAEYCAAAAACi5bZQAAAFEElEQVR4Ae3cMahWdRzGca9Jg6JeXAwCCRsULkYOKYgQIRKCDhddElzS7SZNLm4OiaANKQ5OQUO4llOBlQ2BEGpL4a615a2QLLTC5fn/Dpzvy6v3+L4X+97puc857zmHz/v7w+Hwvu+KFf4poIACCiiggAIKKKCAAgoooIACCiiggAIKKKCAAgoooIACCiiggAIKKKCAAgoooIACCiiggAIKKKCAAgoooIACCigwDYGZaZz08TlfyInXJ/WF91KuTtqStJB0LumdpAdJZ5JOJY0OK0dv/v9uFQbee2GEAQGonRhhQABqJ0YYEIDaiQGYVdA/db0pr3wxaVfS7qTZpINJ44Y72fF80nzSH0k/JF1LGjc4MSAljDAgALUTIwwIQO3ECAMCUDsxwoAA1DPQP2G9PftfTRr9LDe7jR3+yZ7vJt1PauHnxHtJt5PGDS4lkBJGGBCA2okRBgSgdmKEAQGonRhhQADqge58N+Tw15M2J40b2msX85K3kv5OGvqeOgcuwaVUMGoUpmqULEzBqFGYqlGyMAWjRmGqRsnCFIwahakaJQtTMGoc6NMOv+aYJ5L2J91MOp/Uwq3EvUntWe5cuveTJhGcGFAWRhgQgNqJEQYEoHZihAEBqJ0YYUAA6oGe+fYdfV3K9snbS+mOJh1J+jRp+sGlBO+BMMKAANROjDAgALUTIwwIQO3ECAMCUA/0zLfv6L/3lL/1dMfSXU5qn+lNNeHgUgJwYYQBAaidGGFAAGonRhgQgNqJEQYEoH6Gz3z7zrgm5ZWkN5P2JX2ZNK3gUgJ5YYQBAaidGGFAAGonRhgQgNqJEQYEoJ7wnW+7ilcTbyQtJn2d9H3SxaR/k55dcCmBrTDCgADUTowwIAC1EyMMCEDtxAgDAlBP7c63Xc984sdJa5NaOJn4SdIvSUMHlxKICiMMCEDtxAgDAlA7McKAANROjDAgAPUyuPNtV7Yt8cOkPUkttO/JfZDybtIwwaUEjsIIAwJQOzHCgADUTowwIAC1EyMMCEC9rO582zXOJh5Iak+E20V/la17k4YJLiVwFEYYEIDaiREGBKB2YoQBAaidGGFAAOp2Ewk7LJ/6r1xK+0GKh+neTvomaSnBpQR6wggDAlA7McKAANROjDAgALUTIwwIQN1uImGHSdav5WSHkt5I6rvUH7P126RhgksJHIURBgSgdmKEAQGonRhhQABqJ0YYEIC673YSdh223pLDHU+aT3opqS88Stm+4Tb0LwC7lILcDcJ0PfKfMKHoBmG6HvlPmFB0gzBdj/wnTCi6QZiuR/4TJhTdMJFPO7T72MM5+0LSK0mjQ/t9s/a9ts9Hv2QJW50YwBNGGBCA2okRBgSgdmKEAQGonRhhQADqwe98N+ZEc0kXkrYmjQ7Xs/ls0mdJQz/fzYFLcCkVjBqFqRolC1MwahSmapQsTMGoUZiqUbIwBaNGYapGycIUjBqXdOe7IUdqvzP2errNSaPDd9ncfsvsi3R/Jk02ODHgLYwwIAC1EyMMCEDtxAgDAlA7McKAANRj3/nuzAFOJO1IejlpdGj3sR9lx9NJ95OmH1xK8B4IIwwIQO3ECAMCUDsxwoAA1E6MMCAA9djfcJvPAVpKVcJPyVeS2jfSzqVbTFqewaUE74swwoAA1E6MMCAAtRMjDAhA7cQIAwLWCiiggAIKKKCAAgoooIACCiiggAIKKKCAAgoooIACCiiggAIKKKDAcyHwH9qiTVBZInpGAAAAAElFTkSuQmCC\n",
            "image/jpeg": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "def to_pillow_image(x: FloatNDArray, scale: int = 10) -> PIL.Image.Image:\n",
        "    '''Convert example of shape (28 * 28,) and values 0..1 to Pillow image.'''\n",
        "    H = W = 28\n",
        "    assert x.shape == (H * W,) and 0 <= x.min() <= x.max() <= 1\n",
        "    x_int = (x * 255).astype(np.uint8).reshape(H, W)\n",
        "    img = PIL.Image.fromarray(x_int, mode='L')\n",
        "    return img.resize((H * scale, W * scale), PIL.Image.Resampling.NEAREST)\n",
        "\n",
        "\n",
        "display(to_pillow_image(x_train[0]))\n",
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5PPE1ldTNNx"
      },
      "source": [
        "## Exercise 1\n",
        "\n",
        "In this exercise, your task is to fill in the gaps in this code by implementing the backpropagation algorithm.\n",
        "Once done, you can run the network on the MNIST example and see how it performs.  \n",
        "Feel free to play with the parameters. Your model should achieve 90%+ accuracy after a few epochs.  \n",
        "\n",
        "Before you start you should note a few things:\n",
        "+ `backprop` - is the function that you need to implement\n",
        "+ `learning_step` - calls `backprop` to get the gradients for network parameters\n",
        "+ The derivative of the loss is already computed by `cost_derivative`.\n",
        "+ Your goal is to compute $\\frac{d L\\left(\\text{model}(x), y\\right)}{d p}$ for each parameter $p$ of the network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvbfIFaF5_MW"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z: FloatNDArray) -> FloatNDArray:\n",
        "    return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "\n",
        "def sigmoid_prime(z: FloatNDArray) -> FloatNDArray:\n",
        "    '''Derivative of the sigmoid.'''\n",
        "    return sigmoid(z) * (1 - sigmoid(z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsCgwvfHTNN0"
      },
      "outputs": [],
      "source": [
        "class Network:\n",
        "    '''\n",
        "    Multi-Layer Perceptron.\n",
        "\n",
        "    A simple neural network with fully-connected layers and sigmoid activations.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, sizes: Sequence[int] = (784, 30, 10)):\n",
        "        '''\n",
        "        Args:\n",
        "        - sizes: sequence of layer widths [N^0, ... , N^last]\n",
        "          These are lengths of activation vectors, where:\n",
        "          - N^0 is input size: 784.\n",
        "          - N^last is the number of classes into which we can classify each input: 10.\n",
        "        '''\n",
        "        self.sizes = list(sizes)\n",
        "\n",
        "        # We initialize weights and biases with random normal distribution.\n",
        "\n",
        "        # List of len(sizes) - 1 vectors of shape (N^1), (N^2), ..., (N^last).\n",
        "        self.biases = [np.random.randn(n) for n in sizes[1:]]\n",
        "\n",
        "        # List of len(sizes) - 1 matrices of shape (N^i, N^{i-1}).\n",
        "        # Weights are indexed by target node first.\n",
        "        self.weights = [\n",
        "            np.random.randn(n_out, n_in) / np.sqrt(n_in)\n",
        "            for n_in, n_out in zip(sizes[:-1], sizes[1:], strict=True)\n",
        "        ]\n",
        "\n",
        "    def feedforward(self, x: FloatNDArray) -> FloatNDArray:\n",
        "        '''\n",
        "        Run the network on a single case of shape (N^0,).\n",
        "\n",
        "        Returns last layer activations, shape (N^last,), values 0..1.\n",
        "        '''\n",
        "        g = x\n",
        "        for w, b in zip(self.weights, self.biases, strict=True):\n",
        "            f = w @ g + b  # pre-activations\n",
        "            g = sigmoid(f)  # activations\n",
        "        return g\n",
        "\n",
        "    def learning_step(\n",
        "        self, x_mini_batch: FloatNDArray, y_mini_batch: FloatNDArray, learning_rate: float\n",
        "    ) -> None:\n",
        "        '''\n",
        "        Update network parameters with a single mini-batch step of backpropagation and gradient descent.\n",
        "\n",
        "        Args:\n",
        "        - x_mini_batch: shape (B, N^0) where B is the mini-batch size.\n",
        "        - y_mini_batch: shape (B, N^last).\n",
        "        - learning_rate.\n",
        "        '''\n",
        "        # Accumulate gradients by running backprop one dataitem at a time (without vectorization).\n",
        "        grads_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        grads_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        for x, y in zip(x_mini_batch, y_mini_batch):\n",
        "            item_grads_w, item_grads_b = self.backprop(x, y)\n",
        "            for i in range(len(grads_w)):\n",
        "                grads_w[i] = grads_w[i] + item_grads_w[i] / len(x_mini_batch)\n",
        "            for i in range(len(grads_b)):\n",
        "                grads_b[i] = grads_b[i] + item_grads_b[i] / len(x_mini_batch)\n",
        "\n",
        "        # Gradient descent step.\n",
        "        self.weights = [\n",
        "            w - grad_w * learning_rate\n",
        "            for w, grad_w in zip(self.weights, grads_w, strict=True)\n",
        "        ]\n",
        "        self.biases = [\n",
        "            b - grad_b * learning_rate\n",
        "            for b, grad_b in zip(self.biases, grads_b, strict=True)\n",
        "        ]\n",
        "\n",
        "    def backprop(\n",
        "        self, x: FloatNDArray, y: FloatNDArray\n",
        "    ) -> tuple[list[FloatNDArray], list[FloatNDArray]]:\n",
        "        '''\n",
        "        Backpropagation for a single input (not vectorized).\n",
        "\n",
        "        Args:\n",
        "        - x: input features, shape (N^0).\n",
        "        - y: target label (one-hot encoded), shape (N^last).\n",
        "\n",
        "        Returns (grads_w, grads_b), where:\n",
        "        - grads_w is a list of gradients over weights (shape (N^i, N^{i-1})), for each layer.\n",
        "        - grads_b is a list of gradients over biases (shape (N^i)), for each layer.\n",
        "        '''\n",
        "\n",
        "        # Go forward, remembering all activations.\n",
        "        # Pre-activations function, layer by layer, shapes (N^1), ..., (N^last).\n",
        "        fs: list[FloatNDArray] = []\n",
        "        # Activations (including inputs to the first layer), shapes (N^0), (N^1), ..., (N^last).\n",
        "        gs: list[FloatNDArray] = [x]\n",
        "\n",
        "        # TODO\n",
        "        g = x\n",
        "        for w, b in zip(self.weights, self.biases, strict=True):\n",
        "            f = w @ g + b\n",
        "            fs.append(f)\n",
        "            g = sigmoid(f)\n",
        "            gs.append(g)\n",
        "\n",
        "        assert [f.shape for f in fs] == [(n,) for n in self.sizes[1:]], f'Shape mismatch: {[f.shape for f in fs]} vs {self.sizes[1:]}'\n",
        "        assert [g.shape for g in gs] == [(n,) for n in self.sizes], f'Shape mismatch: {[g.shape for g in gs]} vs {self.sizes}'\n",
        "\n",
        "        # Now go backward from the final cost applying backpropagation.\n",
        "        grad_g = self.cost_derivative(gs[-1], y)  # shape initially (N^last), then layer by layer.\n",
        "\n",
        "        # TODO\n",
        "        grad_f_list: list[FloatNDArray] = []  # shapes (N^1), ..., (N^last).\n",
        "        for w, g in reversed(list(zip(self.weights, gs[1:], strict=True))):\n",
        "            grad_f = grad_g * g * (1 - g)  # Element-wise multiplication.\n",
        "            grad_f_list = [grad_f] + grad_f_list\n",
        "            grad_g = w.T @ grad_f  # Multiply shape (N^{i-1}, N^i) by (N^i).\n",
        "\n",
        "        # FIXME the last grad_g (grad over inputs) is not needed,\n",
        "        # and it might be relatively costly for MLP[784,30,10].\n",
        "\n",
        "        assert [gf.shape for gf in grad_f_list] == [(n,) for n in self.sizes[1:]]\n",
        "\n",
        "        grads_w = [\n",
        "            np.outer(grad_f, g)  # Outer product of shape (N^i) by (N^{i-1}).\n",
        "            for grad_f, g in zip(grad_f_list, gs[:-1], strict=True)\n",
        "        ]\n",
        "        grads_b = grad_f_list\n",
        "\n",
        "        for grad_b, b in zip(grads_b, self.biases, strict=True):\n",
        "            assert grad_b.shape == b.shape, f'Shape mismatch: {grad_b.shape=} but {b.shape=}'\n",
        "        for grad_w, w in zip(grads_w, self.weights, strict=True):\n",
        "            assert grad_w.shape == w.shape, f'Shape mismatch: {grad_w.shape=} but {w.shape=}'\n",
        "\n",
        "        return grads_w, grads_b\n",
        "\n",
        "    def cost_derivative(self, a: FloatNDArray, y: FloatNDArray) -> FloatNDArray:\n",
        "        '''\n",
        "        Gradient of loss (MSE) over output activations, for a single sample.\n",
        "\n",
        "        Args:\n",
        "        - a: output activations, shape (N^last).\n",
        "        - y: target values (one-hot encoded labels), shape (N^last).\n",
        "\n",
        "        Returns gradients, shape (N^last).\n",
        "        '''\n",
        "        assert a.shape == y.shape, f'Shape mismatch: {a.shape=} but {y.shape=}'\n",
        "        N_last, = a.shape\n",
        "        return (2 / N_last) * (a - y.astype(np.float64))\n",
        "\n",
        "    def evaluate(\n",
        "        self, x_test_data: FloatNDArray, y_test_data: FloatNDArray\n",
        "    ) -> np.float64:\n",
        "        '''\n",
        "        Compute accuracy: the ratio of correct answers for test_data.\n",
        "\n",
        "        Args (here B is the number of test dataitems):\n",
        "        - x_test_data: shape (B, N^0).\n",
        "        - y_test_data: shape (B, N^last).\n",
        "        '''\n",
        "        test_results: list[bool] = []\n",
        "        for x, y in zip(x_test_data, y_test_data):\n",
        "            output_label: np.int64 = np.argmax(self.feedforward(x))\n",
        "            target_label: np.int64 = np.argmax(y)\n",
        "            test_results.append(output_label == target_label)\n",
        "\n",
        "        return np.mean(test_results)\n",
        "\n",
        "    def SGD(\n",
        "        self,\n",
        "        training_data: tuple[FloatNDArray, FloatNDArray],\n",
        "        test_data: tuple[FloatNDArray, FloatNDArray] | None = None,\n",
        "        epochs: int = 2,\n",
        "        mini_batch_size: int = 100,\n",
        "        learning_rate: float = 1.0,\n",
        "    ) -> None:\n",
        "        x_train, y_train = training_data\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            for i in range(x_train.shape[0] // mini_batch_size):\n",
        "                i_begin = i * mini_batch_size\n",
        "                i_end = (i + 1) * mini_batch_size\n",
        "                self.learning_step(x_train[i_begin:i_end], y_train[i_begin:i_end], learning_rate)\n",
        "            if test_data:\n",
        "                x_test, y_test = test_data\n",
        "                accuracy = self.evaluate(x_test, y_test)\n",
        "                tqdm.write(f'Epoch: {epoch}, Accuracy: {accuracy * 100:.2f} %')\n",
        "            else:\n",
        "                tqdm.write(f'Epoch: {epoch}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CBP5a-30tRF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "d42c38dc121e4da18eb2805f8c7855e7",
            "f5340307900a4097b4d6533f1bd6e3fc",
            "b418e3389c094347bb4c07bd5efa77bc",
            "85b8085f44814800a32d5ae7efb2f343",
            "014b993df2484f139ffd7ff3c7ad49cb",
            "beda20c9c6a146d7a15c2d90f8ceed0e",
            "012ef3d3b370474a9a2756b96643b2b5",
            "6fbaf3a8c8f84bf599009e7d97f162a9",
            "6b7e6927f768481c9b61d43b19709cf0",
            "dceaf6e3830f4223914bfae7d1e0f10f",
            "7d490cbefefc43bd88267df1dcaaa66a"
          ]
        },
        "outputId": "9edc98c4-b350-4418-f90e-234cbc9853a7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d42c38dc121e4da18eb2805f8c7855e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Accuracy: 32.23 %\n",
            "Epoch: 1, Accuracy: 55.50 %\n",
            "Epoch: 2, Accuracy: 68.43 %\n",
            "Epoch: 3, Accuracy: 75.50 %\n",
            "Epoch: 4, Accuracy: 79.27 %\n",
            "CPU times: user 3.18 s, sys: 1.81 ms, total: 3.18 s\n",
            "Wall time: 3.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Smaller test on part of the dataset.\n",
        "# The unvectorized version should take about 2s per epoch\n",
        "# and achieve accuracy ~75% or more (for most executions).\n",
        "network = Network([784, 30, 10])\n",
        "network.SGD(\n",
        "    (x_train[:3000], y_train[:3000]),\n",
        "    test_data=(x_test[:3000], y_test[:3000]),\n",
        "    epochs=5,\n",
        "    mini_batch_size=100,\n",
        "    learning_rate=10.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JSUVlz11rHl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "7fb152f261234978a35f54999c01ac2c",
            "e4eb5f2b6c7d451ea4fcfbc1b952b28d",
            "b3d5f0d7c1894370af81578bbe7b9b4e",
            "e9160d7645084a4893936180715f0fbc",
            "72b8a09cc7d14fe4b0875f9b64e77e23",
            "ce423a1307df478386065354723ab352",
            "4e7d24fb36de475ba88a63673ad788ee",
            "8c8b886c747e4f99babe514b54164ec0",
            "2f703a0d36d34e10b11c1f1e5b414e8e",
            "d63a4b9d557d4d1f94381223b09f96be",
            "64dd68aeea62486381c6991bfe9f04ad"
          ]
        },
        "outputId": "e2478ea2-7e1d-4889-87bb-8d688403b76a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fb152f261234978a35f54999c01ac2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Accuracy: 88.97 %\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-862484764.py\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, test_data, epochs, mini_batch_size, learning_rate)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mi_begin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0mi_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_begin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_begin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-862484764.py\u001b[0m in \u001b[0;36mlearning_step\u001b[0;34m(self, x_mini_batch, y_mini_batch, learning_rate)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mgrads_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mini_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mitem_grads_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_grads_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mgrads_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrads_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem_grads_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mini_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-862484764.py\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         grads_w = [\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Outer product of shape (N^i) by (N^{i-1}).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgrad_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_f_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/numeric.py\u001b[0m in \u001b[0;36mouter\u001b[0;34m(a, b, out)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Full test.\n",
        "# The unvectorized version should take about 20s per epoch\n",
        "# and achieve accuracy ~90% or more.\n",
        "network = Network([784, 30, 10])\n",
        "network.SGD(\n",
        "    (x_train, y_train),\n",
        "    test_data=(x_test, y_test),\n",
        "    epochs=10,\n",
        "    mini_batch_size=100,\n",
        "    learning_rate=5.0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d88s6sr-50HK"
      },
      "source": [
        "## Exercise 2\n",
        "\n",
        "Implement a \"fully vectorized\" version, i.e. one using matrix operations instead of going over examples one by one within a minibatch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01WQss4d5xC-"
      },
      "outputs": [],
      "source": [
        "class NetworkVectorized:\n",
        "    '''Multi-Layer Perceptron with vectorized (batched) methods.'''\n",
        "\n",
        "    def __init__(self, sizes: Sequence[int] = (784, 30, 10)):\n",
        "        '''\n",
        "        Args:\n",
        "        - sizes: sequence of layer widths [N^0, ... , N^last]\n",
        "          These are lengths of activation vectors, where:\n",
        "          - N^0 is input size: 784.\n",
        "          - N^last is the number of classes into which we can classify each input: 10.\n",
        "        '''\n",
        "        self.sizes = list(sizes)\n",
        "\n",
        "        # We initialize weights and biases with random normal distribution.\n",
        "\n",
        "        # List of len(sizes) - 1 vectors of shape (N^1), (N^2), ..., (N^last)\n",
        "        self.biases = [np.random.randn(n) for n in sizes[1:]]\n",
        "\n",
        "        # List of len(sizes) - 1 matrices of shape (N^i, N^{i-1}).\n",
        "        # Weights are indexed by target node first.\n",
        "        self.weights = [\n",
        "            np.random.randn(n_out, n_in) / np.sqrt(n_in)\n",
        "            for n_in, n_out in zip(sizes[:-1], sizes[1:], strict=True)\n",
        "        ]\n",
        "\n",
        "    def feedforward(self, x: FloatNDArray) -> FloatNDArray:\n",
        "        '''\n",
        "        Run the network on a batch of cases of shape (B, N^0), values 0..1.\n",
        "\n",
        "        Returns last layer activations, shape (B, N^last), values 0..1.\n",
        "        '''\n",
        "        g = x\n",
        "        for w, b in zip(self.weights, self.biases, strict=True):\n",
        "            # Multiply w of shape (N^i, N^{i-1}) with g.T of shape (N^{i-1}, B)\n",
        "            # to obtain shape (N^i, B), which is then transposed to (B, N^i).\n",
        "            # Then add shape (N^i), broadcasted to (B, N^i).\n",
        "            g = sigmoid((w @ g.T).T + b)\n",
        "        return g\n",
        "\n",
        "    def learning_step(self, x_mini_batch: FloatNDArray, y_mini_batch: FloatNDArray, learning_rate: float) -> None:\n",
        "        '''\n",
        "        Update network parameters with a single mini-batch step of backpropagation and gradient descent.\n",
        "\n",
        "        Args:\n",
        "        - x_mini_batch: shape (B, N^0) where B is mini_batch_size.\n",
        "        - y_mini_batch: shape (B, N^last).\n",
        "        - learning_rate.\n",
        "        '''\n",
        "        grads_w, grads_b = self.backprop_vectorized(x_mini_batch, y_mini_batch)\n",
        "\n",
        "        # Gradient descent step.\n",
        "        self.weights = [\n",
        "            w - learning_rate * grad_w\n",
        "            for w, grad_w in zip(self.weights, grads_w, strict=True)\n",
        "        ]\n",
        "        self.biases = [\n",
        "            b - learning_rate * grad_b\n",
        "            for b, grad_b in zip(self.biases, grads_b, strict=True)\n",
        "        ]\n",
        "\n",
        "    def backprop_vectorized(\n",
        "        self, x: FloatNDArray, y: FloatNDArray\n",
        "    ) -> tuple[list[FloatNDArray], list[FloatNDArray]]:\n",
        "        '''Backpropagation for a mini-batch (vectorized).\n",
        "\n",
        "        Args:\n",
        "        - x: input, shape (B, N^0)\n",
        "        - y: target label (one-hot encoded), shape (B, N^last)\n",
        "\n",
        "        Returns (grads_w, grads_b), where:\n",
        "        - grads_w: list of gradients over weights (shape (N^i, N^{i-1})), for each layer.\n",
        "        - grads_b: list of gradients over biases (shape (N^i)), for each layer.\n",
        "        '''\n",
        "        B, N0 = x.shape\n",
        "        assert N0 == self.sizes[0]\n",
        "\n",
        "        # Go forward, remembering all activations.\n",
        "\n",
        "        # Values after activation function (including inputs to the first layer),\n",
        "        # shapes (B, N^0), (B, N^1), ..., (B, N^last).\n",
        "        gs: list[FloatNDArray] = [x]\n",
        "\n",
        "        # TODO\n",
        "        g = x\n",
        "        for w, b in zip(self.weights, self.biases, strict=True):\n",
        "            # Multiply shape (N^i, N^{i-1}) by (N^{i-1}, B) and transpose result to (B, N^i).\n",
        "            # Then add shape (N^i), which gets broadcasted to (B, N^i).\n",
        "            f = (w @ g.T).T + b\n",
        "            g = sigmoid(f)\n",
        "            gs.append(g)\n",
        "\n",
        "        assert [g.shape for g in gs] == [(B, n) for n in self.sizes], \\\n",
        "            f'Shape mismatch: {[g.shape for g in gs]} vs {[(B, n) for n in self.sizes]}'\n",
        "\n",
        "        # Now go backward from the final cost applying backpropagation.\n",
        "        grad_g = self.cost_derivative(gs[-1], y)  # shape initially (B, N^last), then layer by layer.\n",
        "\n",
        "        grads_w = []  # shapes (N^last, N^{last-1}), ..., (N^1, N^0)\n",
        "        grads_b = []  # shapes (N^last,), ..., (N^1,)\n",
        "\n",
        "        # TODO\n",
        "        for w, prev_g, g in reversed(list(zip(self.weights, gs[:-1], gs[1:], strict=True))):\n",
        "            grad_f = grad_g * g * (1 - g)  # Shape initially (B, N^last), then layer by layer.\n",
        "            grads_w.append(np.matmul(grad_f.T, prev_g))  # Multiply shape (N^i, B) by (B, N^{i-1})).\n",
        "            grads_b.append(np.sum(grad_f, axis=0))  # shape (N^i)\n",
        "            grad_g = grad_f @ w  # Multiply shape (B, N^i) by (N^i, N^{i-1}).\n",
        "\n",
        "        grads_w.reverse()  # Now shapes (N^1, N^0), ..., (N^last, N^{last-1}).\n",
        "        grads_b.reverse()  # Now shapes (N^1,) ..., (N^last,).\n",
        "\n",
        "        for grad_b, b in zip(grads_b, self.biases, strict=True):\n",
        "            assert grad_b.shape == b.shape, f'Shape mismatch: {grad_b.shape=} but {b.shape=}'\n",
        "        for grad_w, w in zip(grads_w, self.weights, strict=True):\n",
        "            assert grad_w.shape == w.shape, f'Shape mismatch: {grad_w.shape=} but {w.shape=}'\n",
        "\n",
        "        return grads_w, grads_b\n",
        "\n",
        "    def cost_derivative(self, a: FloatNDArray, y: FloatNDArray) -> FloatNDArray:\n",
        "        '''\n",
        "        Gradient of loss (MSE) over output activations.\n",
        "\n",
        "        Args:\n",
        "        - a: output activations, shape (B, N^last).\n",
        "        - y: target values (one-hot encoded labels), shape (B, N^last).\n",
        "\n",
        "        Returns gradients, shape (B, N^last).\n",
        "        '''\n",
        "        assert a.shape == y.shape, f'Shape mismatch: {a.shape=} but {y.shape=}'\n",
        "        B, N_last = a.shape\n",
        "        return (2 / (B * N_last)) * (a - y.astype(np.float64))\n",
        "\n",
        "    def evaluate(self, x_test_data: FloatNDArray, y_test_data: FloatNDArray) -> np.float64:\n",
        "        '''\n",
        "        Compute accuracy: the ratio of correct answers for test_data.\n",
        "\n",
        "        Args:\n",
        "        - x_test_data: shape (B, N^0).\n",
        "        - y_test_data: shape (B, N^last).\n",
        "        '''\n",
        "        predictions = np.argmax(self.feedforward(x_test_data), axis=1)\n",
        "        targets = np.argmax(y_test_data, axis=1)\n",
        "        return np.mean(predictions == targets)\n",
        "\n",
        "    def SGD(\n",
        "        self,\n",
        "        training_data: tuple[FloatNDArray, FloatNDArray],\n",
        "        test_data: tuple[FloatNDArray, FloatNDArray] | None = None,\n",
        "        epochs: int = 2,\n",
        "        mini_batch_size: int = 100,\n",
        "        learning_rate: float = 1.0\n",
        "    ) -> None:\n",
        "        x_train, y_train = training_data\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            for i in range(x_train.shape[0] // mini_batch_size):\n",
        "                i_begin = i * mini_batch_size\n",
        "                i_end = (i + 1) * mini_batch_size\n",
        "                self.learning_step(x_train[i_begin:i_end], y_train[i_begin:i_end], learning_rate)\n",
        "            if test_data:\n",
        "                x_test, y_test = test_data\n",
        "                accuracy = self.evaluate(x_test, y_test)\n",
        "                print(f'Epoch: {epoch}, Accuracy: {accuracy * 100:.2f} %')\n",
        "            else:\n",
        "                print(f'Epoch: {epoch}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjyZVxp59pxG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951,
          "referenced_widgets": [
            "57161b22ccd640eaae6641f367e1cc3e",
            "66346aa9c6db4d44879e6608509793b2",
            "e81a6eebab334e37ab82cb78c84fec63",
            "4c0aa6a7e2da46b78c6d0a814e0b4496",
            "d9a701f24b6e40eb8fd997785c52a88e",
            "d26c548f742540589cdb20bf5a3ee6be",
            "33fe6c4123d440bdaeb2ad75c1a35142",
            "cacff7d28fc84d33a94746c173f3fc19",
            "91837169ead24b34a639175a43e51d1c",
            "bf00069d2b5f417987c55ce108589990",
            "19dbb874f31c4ce2a206e85f14ea7ac3"
          ]
        },
        "outputId": "19d1fb7d-df7d-4ac6-925f-dec3f46bbd81"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57161b22ccd640eaae6641f367e1cc3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Accuracy: 88.99 %\n",
            "Epoch: 1, Accuracy: 90.94 %\n",
            "Epoch: 2, Accuracy: 91.91 %\n",
            "Epoch: 3, Accuracy: 92.55 %\n",
            "Epoch: 4, Accuracy: 92.93 %\n",
            "Epoch: 5, Accuracy: 93.25 %\n",
            "Epoch: 6, Accuracy: 93.60 %\n",
            "Epoch: 7, Accuracy: 93.78 %\n",
            "Epoch: 8, Accuracy: 93.96 %\n",
            "Epoch: 9, Accuracy: 94.16 %\n",
            "Epoch: 10, Accuracy: 94.27 %\n",
            "Epoch: 11, Accuracy: 94.35 %\n",
            "Epoch: 12, Accuracy: 94.53 %\n",
            "Epoch: 13, Accuracy: 94.55 %\n",
            "Epoch: 14, Accuracy: 94.69 %\n",
            "Epoch: 15, Accuracy: 94.79 %\n",
            "Epoch: 16, Accuracy: 94.84 %\n",
            "Epoch: 17, Accuracy: 94.94 %\n",
            "Epoch: 18, Accuracy: 95.00 %\n",
            "Epoch: 19, Accuracy: 95.07 %\n",
            "Epoch: 20, Accuracy: 95.09 %\n",
            "Epoch: 21, Accuracy: 95.14 %\n",
            "Epoch: 22, Accuracy: 95.24 %\n",
            "Epoch: 23, Accuracy: 95.27 %\n",
            "Epoch: 24, Accuracy: 95.30 %\n",
            "Epoch: 25, Accuracy: 95.36 %\n",
            "Epoch: 26, Accuracy: 95.40 %\n",
            "Epoch: 27, Accuracy: 95.44 %\n",
            "Epoch: 28, Accuracy: 95.53 %\n",
            "Epoch: 29, Accuracy: 95.57 %\n",
            "Epoch: 30, Accuracy: 95.62 %\n",
            "Epoch: 31, Accuracy: 95.63 %\n",
            "Epoch: 32, Accuracy: 95.62 %\n",
            "Epoch: 33, Accuracy: 95.65 %\n",
            "Epoch: 34, Accuracy: 95.67 %\n",
            "Epoch: 35, Accuracy: 95.68 %\n",
            "Epoch: 36, Accuracy: 95.71 %\n",
            "Epoch: 37, Accuracy: 95.73 %\n",
            "Epoch: 38, Accuracy: 95.77 %\n",
            "Epoch: 39, Accuracy: 95.81 %\n",
            "Epoch: 40, Accuracy: 95.82 %\n",
            "Epoch: 41, Accuracy: 95.87 %\n",
            "Epoch: 42, Accuracy: 95.88 %\n",
            "Epoch: 43, Accuracy: 95.89 %\n",
            "Epoch: 44, Accuracy: 95.90 %\n",
            "Epoch: 45, Accuracy: 95.87 %\n",
            "Epoch: 46, Accuracy: 95.86 %\n",
            "Epoch: 47, Accuracy: 95.88 %\n",
            "Epoch: 48, Accuracy: 95.91 %\n",
            "Epoch: 49, Accuracy: 95.93 %\n",
            "CPU times: user 1min 37s, sys: 153 ms, total: 1min 37s\n",
            "Wall time: 58 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# The vectorized version takes about ~1s per epoch.\n",
        "network = NetworkVectorized([784, 30, 10])\n",
        "network.SGD(\n",
        "    (x_train, y_train),\n",
        "    test_data=(x_test, y_test),\n",
        "    epochs=50,\n",
        "    mini_batch_size=100,\n",
        "    learning_rate=5.0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nIZiS_Ze42M"
      },
      "source": [
        "# Exercise 3 (optional)\n",
        "\n",
        "The standard backpropagation method requires memorization of all outputs of all layers computed during the forward pass, for use in the backward pass, which can take much of precious GPU memory.\n",
        "Instead of doing that, one can checkpoint (memorize) only activations of a select few layers and then recompute the rest as they are needed (redoing the forward pass between checkpoints).  \n",
        "Your task is to complete the code below to implement backpropagation with checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRdWr074ffey",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "0794cec7-7b69-4d8e-d33f-e6e477630ee8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (ipython-input-2673525836.py, line 56)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2673525836.py\"\u001b[0;36m, line \u001b[0;32m56\u001b[0m\n\u001b[0;31m    assert g.shape == grad_g.shape == (B, self.sizes[end_i])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "class NetworkWithCheckpoints(NetworkVectorized):\n",
        "    '''Multi-Layer Perceptron with gradient checkpointing.'''\n",
        "\n",
        "    def __init__(self, sizes: Sequence[int] = (784, 30, 10), checkpoints: Sequence[int] = (1,)):\n",
        "        '''\n",
        "        Args:\n",
        "        - sizes: sequence of layer widths [N^0, ... , N^last]\n",
        "          These are lengths of activation vectors, where:\n",
        "          - N^0 is input size: 784.\n",
        "          - N^last is the number of classes into which we can classify each input: 10.\n",
        "        - checkpoints: Indices of layers whose activations we want to checkpoint\n",
        "          (between 1 and last inclusive (last=len(sizes) - 1).\n",
        "        '''\n",
        "        super().__init__(sizes)\n",
        "        last_layer_id = len(sizes) - 1\n",
        "        # Always store the input and last activations.\n",
        "        self.checkpoints = sorted(set(checkpoints) | {0, last_layer_id})\n",
        "\n",
        "    def backprop_generator(\n",
        "        self, x: FloatNDArray, y: FloatNDArray\n",
        "    ) -> Iterator[tuple[FloatNDArray, FloatNDArray]]:\n",
        "        '''\n",
        "        Backpropagation for a mini-batch (vectorized).\n",
        "\n",
        "        Args:\n",
        "        - x: input, shape (B, N^0)\n",
        "        - y: target label (one-hot encoded), shape (B, N^last)\n",
        "\n",
        "        Yields (grad_w, grad_b) for each layer from i=last down to i=1, where:\n",
        "        - grads_w: shape (N^i, N^{i-1})).\n",
        "        - grads_b: shape (N^i)).\n",
        "        '''\n",
        "        B, N0 = x.shape\n",
        "        assert N0 == self.sizes[0]\n",
        "\n",
        "        # Go forward, remembering only some activations and no pre-activations.\n",
        "\n",
        "        # Values after activation function (including inputs to the first layer),\n",
        "        # shapes (B, N^0), (B, N^1), ..., (B, N^last);\n",
        "        # layers that are not checkpointed get None instead.\n",
        "        gs: list[FloatNDArray | None] = [x]\n",
        "\n",
        "        # TODO forward pass.\n",
        "        g = x\n",
        "\n",
        "        # Now go backward from the final cost applying backpropagation.\n",
        "        grad_g = self.cost_derivative(g, y)  # shape initially (B, N^last), then layer by layer.\n",
        "\n",
        "        # TODO backward pass.\n",
        "        # for each interval between consecutive checkpoints:\n",
        "            # Forward pass to restore intermediate activations.\n",
        "            # for all layers in interval:\n",
        "            # ...\n",
        "\n",
        "            # Now g and grad_g have shape (B, N^{end_i}).\n",
        "            assert g.shape == grad_g.shape == (B, self.sizes[end_i])\n",
        "\n",
        "            # Backward pass between the checkpoints.\n",
        "            # for all layers in the interval, backwards:\n",
        "            #   # Compute grad_w, grad_b.\n",
        "            #   # Yield them as we go, instead of returning a list.\n",
        "            #   # https://docs.python.org/3/tutorial/classes.html#generators\n",
        "            #   yield (grad_w, grad_b)\n",
        "\n",
        "            # Now grad_g has shape (B, N^{start_i}).\n",
        "            assert grad_g.shape == (B, self.sizes[start_i])\n",
        "\n",
        "    @override\n",
        "    def learning_step(self, x_mini_batch: FloatNDArray, y_mini_batch: FloatNDArray, learning_rate: float) -> None:\n",
        "        '''\n",
        "        Update network parameters with a single mini-batch step of backpropagation and gradient descent.\n",
        "\n",
        "        Args:\n",
        "        - x_mini_batch: shape (B, N^0) where B is mini_batch_size.\n",
        "        - y_mini_batch: shape (B, N^last).\n",
        "        - learning_rate.\n",
        "        '''\n",
        "        indices = range(len(self.sizes) - 1, 0, -1)  # From `last` down to 1 inclusive.\n",
        "        for i, (grad_w, grad_b) in zip(indices, self.backprop_generator(x_mini_batch, y_mini_batch), strict=True):\n",
        "            self.weights[i - 1] = self.weights[i - 1] - learning_rate * grad_w\n",
        "            self.biases[i - 1] = self.biases[i - 1] - learning_rate * grad_b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5iezw0nfgve"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Compare on the same seed, results should be exactly the same.\n",
        "\n",
        "np.random.seed(42)\n",
        "network = NetworkWithCheckpoints([784, 20, 15, 13, 10], checkpoints=[2])\n",
        "network.SGD(\n",
        "    (x_train, y_train),\n",
        "    test_data=(x_test, y_test),\n",
        "    epochs=1,\n",
        "    mini_batch_size=100,\n",
        "    learning_rate=50.\n",
        ")\n",
        "\n",
        "np.random.seed(42)\n",
        "network = NetworkVectorized([784, 20, 15, 13, 10])\n",
        "network.SGD(\n",
        "    (x_train, y_train),\n",
        "    test_data=(x_test, y_test),\n",
        "    epochs=1,\n",
        "    mini_batch_size=100,\n",
        "    learning_rate=50.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Memory usage can be checked by installing `memory_profiler` and using `%%memit` (instead of `%%time`),\n",
        " but it will be very hard to see a difference from checkpointing for an MLP."
      ],
      "metadata": {
        "id": "p2-bXJfTJOhD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9w3OzXKe42N"
      },
      "source": [
        "# JAX Playground (Optional)\n",
        "JAX is a framework that allows the creation of neural networks with numpy-like syntax.  \n",
        "In this course, we will use Pytorch instead of JAX, but for this lab scenario, JAX can help us test our gradient computation implementation.  \n",
        "Let's give it a try  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUd116BMe42O"
      },
      "outputs": [],
      "source": [
        "!pip3 install jax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaZVxk4ze42O"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from textwrap import dedent\n",
        "\n",
        "\n",
        "def jax_sigmoid(z: jax.Array) -> jax.Array:\n",
        "    return 1.0 / (1.0 + jnp.exp(-z))\n",
        "\n",
        "\n",
        "def jax_sigmoid_prime(z: jax.Array) -> jax.Array:\n",
        "    return sigmoid(z) * (1 - sigmoid(z))\n",
        "\n",
        "\n",
        "# Define a jax function.\n",
        "# We emphasize that this is a function, not a jax procedure,\n",
        "# and in fact there are more requirements for writing good jax code,\n",
        "# but this is just an example.\n",
        "# (see https://jax.readthedocs.io/en/latest/tutorials.html)\n",
        "def jax_forward(x: jax.Array, w: jax.Array, b: jax.Array) -> jax.Array:\n",
        "    # f = TODO\n",
        "    g = jax_sigmoid(f)\n",
        "    loss = g.sum()  # Just a dummy loss for simplicity.\n",
        "    return loss, g\n",
        "\n",
        "\n",
        "# This will calculate gradient for first, second, and third argument.\n",
        "# has_aux tells that in addition to loss our function returns something more.\n",
        "auto_backward = jax.value_and_grad(fun=jax_forward, argnums=[0, 1, 2], has_aux=True)\n",
        "\n",
        "\n",
        "def manual_backward(x: jax.Array, w: jax.Array, b: jax.Array) -> jax.Array:\n",
        "    # f = TODO\n",
        "    grad_g = jnp.ones_like(f)  # Grad of the dummy loss over activations g.\n",
        "    # grad_f = TODO\n",
        "    # grad_b = TODO\n",
        "    # grad_w = TODO\n",
        "    # grad_x = TODO\n",
        "    return grad_x, grad_w, grad_b\n",
        "\n",
        "\n",
        "def example():\n",
        "    B, N0, N1 = 3, 5, 7\n",
        "\n",
        "    key = jax.random.key(42)\n",
        "    key, subkey = jax.random.split(key)\n",
        "    w = jax.random.normal(subkey, (N1, N0))\n",
        "    key, subkey = jax.random.split(key)\n",
        "    b = jax.random.normal(subkey, (N1,))\n",
        "    x = jnp.arange(N0, dtype=w.dtype).reshape(1, N0) * jnp.ones((B, N0))\n",
        "\n",
        "    (loss, res), (jax_dx, jax_dw, jax_db) = auto_backward(x, w, b)\n",
        "    dx, dw, db = manual_backward(x, w, b)\n",
        "\n",
        "    print(dedent(f'''\n",
        "        diff dx = {jnp.mean(jnp.abs(jax_dx - dx))}\n",
        "        diff dw = {jnp.mean(jnp.abs(jax_dw - dw))}\n",
        "        diff db = {jnp.mean(jnp.abs(jax_db - db))}\n",
        "        dtype={dx.dtype} (eps={np.finfo(dx.dtype).eps})\n",
        "    ''').strip())\n",
        "\n",
        "\n",
        "example()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d42c38dc121e4da18eb2805f8c7855e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5340307900a4097b4d6533f1bd6e3fc",
              "IPY_MODEL_b418e3389c094347bb4c07bd5efa77bc",
              "IPY_MODEL_85b8085f44814800a32d5ae7efb2f343"
            ],
            "layout": "IPY_MODEL_014b993df2484f139ffd7ff3c7ad49cb"
          }
        },
        "f5340307900a4097b4d6533f1bd6e3fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beda20c9c6a146d7a15c2d90f8ceed0e",
            "placeholder": "​",
            "style": "IPY_MODEL_012ef3d3b370474a9a2756b96643b2b5",
            "value": "100%"
          }
        },
        "b418e3389c094347bb4c07bd5efa77bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fbaf3a8c8f84bf599009e7d97f162a9",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b7e6927f768481c9b61d43b19709cf0",
            "value": 5
          }
        },
        "85b8085f44814800a32d5ae7efb2f343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dceaf6e3830f4223914bfae7d1e0f10f",
            "placeholder": "​",
            "style": "IPY_MODEL_7d490cbefefc43bd88267df1dcaaa66a",
            "value": " 5/5 [00:03&lt;00:00,  1.65it/s]"
          }
        },
        "014b993df2484f139ffd7ff3c7ad49cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beda20c9c6a146d7a15c2d90f8ceed0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "012ef3d3b370474a9a2756b96643b2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fbaf3a8c8f84bf599009e7d97f162a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b7e6927f768481c9b61d43b19709cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dceaf6e3830f4223914bfae7d1e0f10f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d490cbefefc43bd88267df1dcaaa66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fb152f261234978a35f54999c01ac2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4eb5f2b6c7d451ea4fcfbc1b952b28d",
              "IPY_MODEL_b3d5f0d7c1894370af81578bbe7b9b4e",
              "IPY_MODEL_e9160d7645084a4893936180715f0fbc"
            ],
            "layout": "IPY_MODEL_72b8a09cc7d14fe4b0875f9b64e77e23"
          }
        },
        "e4eb5f2b6c7d451ea4fcfbc1b952b28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce423a1307df478386065354723ab352",
            "placeholder": "​",
            "style": "IPY_MODEL_4e7d24fb36de475ba88a63673ad788ee",
            "value": " 10%"
          }
        },
        "b3d5f0d7c1894370af81578bbe7b9b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c8b886c747e4f99babe514b54164ec0",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f703a0d36d34e10b11c1f1e5b414e8e",
            "value": 1
          }
        },
        "e9160d7645084a4893936180715f0fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d63a4b9d557d4d1f94381223b09f96be",
            "placeholder": "​",
            "style": "IPY_MODEL_64dd68aeea62486381c6991bfe9f04ad",
            "value": " 1/10 [00:18&lt;01:54, 12.73s/it]"
          }
        },
        "72b8a09cc7d14fe4b0875f9b64e77e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce423a1307df478386065354723ab352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e7d24fb36de475ba88a63673ad788ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c8b886c747e4f99babe514b54164ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f703a0d36d34e10b11c1f1e5b414e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d63a4b9d557d4d1f94381223b09f96be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64dd68aeea62486381c6991bfe9f04ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57161b22ccd640eaae6641f367e1cc3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66346aa9c6db4d44879e6608509793b2",
              "IPY_MODEL_e81a6eebab334e37ab82cb78c84fec63",
              "IPY_MODEL_4c0aa6a7e2da46b78c6d0a814e0b4496"
            ],
            "layout": "IPY_MODEL_d9a701f24b6e40eb8fd997785c52a88e"
          }
        },
        "66346aa9c6db4d44879e6608509793b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d26c548f742540589cdb20bf5a3ee6be",
            "placeholder": "​",
            "style": "IPY_MODEL_33fe6c4123d440bdaeb2ad75c1a35142",
            "value": "100%"
          }
        },
        "e81a6eebab334e37ab82cb78c84fec63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cacff7d28fc84d33a94746c173f3fc19",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91837169ead24b34a639175a43e51d1c",
            "value": 50
          }
        },
        "4c0aa6a7e2da46b78c6d0a814e0b4496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf00069d2b5f417987c55ce108589990",
            "placeholder": "​",
            "style": "IPY_MODEL_19dbb874f31c4ce2a206e85f14ea7ac3",
            "value": " 50/50 [00:57&lt;00:00,  1.05it/s]"
          }
        },
        "d9a701f24b6e40eb8fd997785c52a88e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d26c548f742540589cdb20bf5a3ee6be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33fe6c4123d440bdaeb2ad75c1a35142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cacff7d28fc84d33a94746c173f3fc19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91837169ead24b34a639175a43e51d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf00069d2b5f417987c55ce108589990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19dbb874f31c4ce2a206e85f14ea7ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}